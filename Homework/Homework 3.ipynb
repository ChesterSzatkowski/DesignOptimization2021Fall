{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "harmful-logging",
   "metadata": {},
   "source": [
    "### Problem 1 (50 points) \n",
    "\n",
    "Vapor-liquid equilibria data are correlated using two adjustable parameters $A_{12}$ and $A_{21}$ per binary\n",
    "mixture. For low pressures, the equilibrium relation can be formulated as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p = & x_1\\exp\\left(A_{12}\\left(\\frac{A_{21}x_2}{A_{12}x_1+A_{21}x_2}\\right)^2\\right)p_{water}^{sat}\\\\\n",
    "& + x_2\\exp\\left(A_{21}\\left(\\frac{A_{12}x_1}{A_{12}x_1+A_{21}x_2}\\right)^2\\right)p_{1,4 dioxane}^{sat}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Here the saturation pressures are given by the Antoine equation\n",
    "\n",
    "$$\n",
    "\\log_{10}(p^{sat}) = a_1 - \\frac{a_2}{T + a_3},\n",
    "$$\n",
    "\n",
    "where $T = 20$($^{\\circ}{\\rm C}$) and $a_{1,2,3}$ for a water - 1,4 dioxane\n",
    "system is given below.\n",
    "\n",
    "|             | $a_1$     | $a_2$      | $a_3$     |\n",
    "|:------------|:--------|:---------|:--------|\n",
    "| Water       | 8.07131 | 1730.63  | 233.426 |\n",
    "| 1,4 dioxane | 7.43155 | 1554.679 | 240.337 |\n",
    "\n",
    "\n",
    "The following table lists the measured data. Recall that in a binary system $x_1 + x_2 = 1$.\n",
    "\n",
    "|$x_1$ | 0.0 | 0.1 | 0.2 | 0.3 | 0.4 | 0.5 | 0.6 | 0.7 | 0.8 | 0.9 | 1.0 |\n",
    "|:-----|:--------|:---------|:--------|:-----|:-----|:-----|:-----|:-----|:-----|:-----|:-----|\n",
    "|$p$| 28.1 | 34.4 | 36.7 | 36.9 | 36.8 | 36.7 | 36.5 | 35.4 | 32.9 | 27.7 | 17.5 |\n",
    "\n",
    "Estimate $A_{12}$ and $A_{21}$ using data from the above table: \n",
    "\n",
    "1. Formulate the least square problem; \n",
    "2. Since the model is nonlinear, the problem does not have an analytical solution. Therefore, solve it using the gradient descent or Newton's method implemented in HW1; \n",
    "3. Compare your optimized model with the data. Does your model fit well with the data?\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c18f994",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{A_{12},A_{21}}\\sum_{i=1}^{11} (p(x_i;A_{12},A_{21})-p_i)^2\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "infectious-remark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.9584166 1.6891807]\n",
      "0.67019147\n",
      "tensor([28.8241, 34.6443, 36.4530, 36.8673, 36.8740, 36.7498, 36.3904, 35.3848,\n",
      "        32.9478, 27.7300, 17.4733])\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Fix the step size\n",
    "a = 0.001\n",
    "\n",
    "# Define a variable, make sure requires_grad=True so that PyTorch can take gradient with respect to this variable\n",
    "A = Variable(t.tensor([2.0, 1.0]), requires_grad=True)\n",
    "\n",
    "# Define a loss\n",
    "pSatWater = 17.4733\n",
    "pSatD = 28.8241\n",
    "pData = t.tensor([28.1, 34.4, 36.7, 36.9, 36.8, 36.7, 36.5, 35.4, 32.9, 27.7, 17.5])\n",
    "x1 = t.tensor([0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "x2 = 1-x1\n",
    "\n",
    "\n",
    "# Start gradient descent\n",
    "for i in range(1000):  # TODO: change the termination criterion\n",
    "    \n",
    "    pEqn = lambda A, x1, x2, pSatD, pSatWater: x1*t.exp(A[0]*(((A[1]*x2)/(A[0]*x1+A[1]*x2))**2))*pSatWater + x2*t.exp(A[1]*(((A[0]*x1)/(A[0]*x1+A[1]*x2))**2))*pSatD\n",
    "    loss = t.sum((pEqn(A,x1,x2,pSatD,pSatWater)-pData)**2)\n",
    "    loss.backward()\n",
    "    \n",
    "    # no_grad() specifies that the operations within this context are not part of the computational graph, i.e., we don't need the gradient descent algorithm itself to be differentiable with respect to x\n",
    "    with t.no_grad():\n",
    "        A -= a * A.grad\n",
    "        \n",
    "        # need to clear the gradient at every step, or otherwise it will accumulate...\n",
    "        A.grad.zero_()\n",
    "        \n",
    "print(A.data.numpy())\n",
    "print(loss.data.numpy())\n",
    "\n",
    "aFinal = ([1.9584166, 1.6891807])\n",
    "finalEqn = pEqn(aFinal, x1, x2, pSatD, pSatWater)\n",
    "print(finalEqn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eb44d4",
   "metadata": {},
   "source": [
    "We see that the numbers become very close to the provided data points. This is backed up by the small loss value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f103891",
   "metadata": {},
   "source": [
    "### Problem 2 (50 points) \n",
    "\n",
    "Solve the following problem using Bayesian Optimization:\n",
    "$$\n",
    "    \\min_{x_1, x_2} \\quad \\left(4-2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2,\n",
    "$$\n",
    "for $x_1 \\in [-3,3]$ and $x_2 \\in [-2,2]$. A tutorial on Bayesian Optimization can be found [here](https://thuijskens.github.io/2016/12/29/bayesian-optimisation/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "painful-climb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CJ\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:509: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\CJ\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:509: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\CJ\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:509: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\CJ\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:509: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\CJ\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:509: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\CJ\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:509: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\CJ\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:509: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\CJ\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:509: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\CJ\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:509: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\CJ\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:509: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\CJ\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:509: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\CJ\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:509: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\CJ\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:509: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\CJ\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:509: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph shows that we converge, therefore, we can take the last values\n",
      "[[-1.75837187e+00 -5.68826950e-01]\n",
      " [-8.64017087e-01  1.05073290e+00]\n",
      " [ 1.00414601e+00 -2.33295751e-01]\n",
      " [ 1.88886930e+00  2.57477708e-02]\n",
      " [ 1.66370070e+00  1.50840240e+00]\n",
      " [ 1.46584935e+00 -4.65316173e-01]\n",
      " [ 1.16164496e+00 -1.45435212e+00]\n",
      " [-1.22338603e+00  3.64454546e-01]\n",
      " [-1.77104099e+00  1.02515820e+00]\n",
      " [-2.42803102e+00  4.83469549e-01]\n",
      " [-1.81757717e+00 -5.38333411e-01]\n",
      " [-1.42156493e+00  1.10729391e+00]\n",
      " [-6.07307656e-01  4.24037140e-01]\n",
      " [-7.21569803e-01 -1.66897820e-01]\n",
      " [-1.80795430e+00  1.60975652e+00]\n",
      " [-1.53512194e+00  8.09806091e-01]\n",
      " [-9.51377300e-01  6.63849490e-01]\n",
      " [-3.58666788e-02  1.84167419e-01]\n",
      " [-1.10853885e-01  6.64517300e-01]\n",
      " [ 2.99887865e-01  5.33348037e-01]\n",
      " [-3.17701862e-02  1.10562396e+00]\n",
      " [-1.66070021e+00 -1.67815372e+00]\n",
      " [ 3.00000000e+00 -7.38169783e-01]\n",
      " [ 1.46145558e+00  1.98636346e-01]\n",
      " [ 1.92046277e-01 -9.25218424e-01]\n",
      " [ 1.57725737e-01 -2.00000000e+00]\n",
      " [ 3.26710146e-01 -5.56724657e-01]\n",
      " [ 8.22441304e-01 -8.20267164e-01]\n",
      " [-1.36743259e-01 -5.67690106e-01]\n",
      " [ 1.05365907e-01  2.00000000e+00]\n",
      " [-3.00000000e+00 -1.24653503e+00]\n",
      " [-1.59028892e+00 -1.58316222e-01]\n",
      " [-4.36025411e-01  1.79529310e+00]\n",
      " [-2.08840396e+00  5.65947333e-01]\n",
      " [-1.94542553e+00 -1.72967306e+00]\n",
      " [-2.50256303e-01 -1.63984652e+00]\n",
      " [-6.62510411e-01 -8.68878745e-01]\n",
      " [ 1.16643755e+00  9.55769632e-01]\n",
      " [-9.71507322e-01  1.62430420e+00]\n",
      " [-2.77059755e+00 -7.56752883e-01]\n",
      " [ 2.63742019e+00 -3.56887497e-03]\n",
      " [ 1.54740434e+00  1.60163489e+00]\n",
      " [ 1.90305855e+00  6.69077279e-01]\n",
      " [ 1.08457455e+00  1.36274814e+00]\n",
      " [-2.46830868e+00 -1.86722052e+00]\n",
      " [ 1.15917326e+00 -8.16693096e-01]\n",
      " [ 1.28673396e+00 -7.71644550e-02]\n",
      " [-2.30925182e-01 -8.74774427e-01]\n",
      " [ 1.38902024e+00 -5.48011862e-01]\n",
      " [ 1.22576578e+00 -1.56731809e+00]\n",
      " [ 8.01214422e-01  1.34868474e+00]\n",
      " [-1.95215772e+00  1.22439035e+00]\n",
      " [ 1.55958878e+00  9.07853842e-01]\n",
      " [-2.00743345e+00  1.87380805e+00]\n",
      " [ 1.95823325e+00 -1.28852831e+00]\n",
      " [ 1.57783469e+00 -1.06082392e+00]\n",
      " [-1.97058982e+00 -2.19518155e-01]\n",
      " [-1.55516258e-02  9.62915760e-01]\n",
      " [-1.60785041e+00  2.32916172e-01]\n",
      " [-1.23288049e+00  8.51789532e-01]\n",
      " [-8.13973197e-01  1.91887956e+00]\n",
      " [-1.98424132e+00  1.84570471e+00]\n",
      " [-1.53638200e+00 -1.68812821e+00]\n",
      " [-2.75630150e+00 -1.91133246e+00]\n",
      " [ 2.65926758e+00  1.99782854e+00]\n",
      " [-4.10691394e-01  8.79239492e-01]\n",
      " [ 5.67182381e-01  8.25340713e-01]\n",
      " [ 4.25374718e-01  5.50561703e-04]\n",
      " [-1.12100066e+00 -5.66803305e-01]\n",
      " [ 8.35060417e-02 -7.23490736e-01]\n",
      " [-1.33528480e-02 -2.23629293e-01]\n",
      " [ 7.92722074e-01  4.09947052e-01]\n",
      " [-4.73337161e-01 -5.33885686e-01]\n",
      " [-1.76994728e+00  6.25759324e-01]\n",
      " [ 4.48776002e-01 -7.84374981e-01]\n",
      " [-3.43011231e-01  1.79889207e-02]\n",
      " [-2.75633911e-01  4.70428724e-01]\n",
      " [ 6.50010311e-01 -5.03940810e-01]\n",
      " [ 1.83620112e-01  7.74895791e-01]\n",
      " [ 3.38248802e-02  4.90823639e-01]\n",
      " [-4.64193471e-01  6.68654662e-01]\n",
      " [ 9.72236898e-02 -4.78073891e-01]\n",
      " [-2.11552145e-01  8.19761980e-01]\n",
      " [ 2.48767360e-01 -7.52032082e-01]\n",
      " [ 2.84583043e-01 -2.80239185e-01]\n",
      " [-1.59877967e-02 -8.50377977e-01]\n",
      " [ 2.34520738e-01  2.58001121e-01]\n",
      " [ 1.75439937e+00  3.87387909e-01]\n",
      " [-2.67687643e-01 -3.22612111e-01]\n",
      " [ 3.01742859e-02  7.10412427e-01]\n",
      " [-6.68453107e-01  7.89915293e-01]\n",
      " [ 1.62555215e+00 -7.44912413e-01]\n",
      " [-1.00987913e-01 -7.20518975e-01]\n",
      " [-1.90087850e+00  8.25109360e-01]\n",
      " [ 1.44579112e+00 -8.22249828e-01]\n",
      " [-2.71361304e-01  6.72681799e-01]\n",
      " [-3.19304186e-01 -7.02396851e-01]\n",
      " [ 2.98073487e-01  9.67399817e-01]\n",
      " [-1.45603721e+00  5.79412642e-01]\n",
      " [ 1.34489094e-01 -1.75425305e-02]\n",
      " [ 9.60977785e-01 -5.89116981e-01]\n",
      " [-7.24474572e-02  7.85797141e-01]\n",
      " [ 1.90217491e-02 -6.15249718e-01]\n",
      " [ 1.71865520e-01 -6.25726702e-01]\n",
      " [-1.17920633e-01  5.18070863e-01]\n",
      " [-4.01858069e-01  1.08790900e+00]\n",
      " [-1.12502761e+00 -9.32387024e-02]\n",
      " [ 1.35805356e-01 -8.14760193e-01]\n",
      " [ 5.60564209e-01 -9.70351389e-01]\n",
      " [ 4.93105850e-01  3.72395254e-01]\n",
      " [ 1.28331908e-01  6.19070145e-01]\n",
      " [-2.62526124e-01  2.72176909e-01]\n",
      " [-7.60951110e-01 -5.59066638e-01]\n",
      " [ 3.52946388e-01  7.20659718e-01]\n",
      " [-1.97302469e-02  6.14844457e-01]\n",
      " [ 3.25914217e-01 -8.61189004e-01]\n",
      " [ 1.20307639e+00  5.46596494e-01]\n",
      " [-5.98777226e-02 -4.29073266e-01]\n",
      " [-8.36490294e-01  2.30405778e-01]\n",
      " [ 1.17400357e-03 -7.29847596e-01]\n",
      " [ 6.06896278e-01 -2.31898509e-01]\n",
      " [ 1.66039037e+00 -2.11262201e-01]\n",
      " [-1.56240390e-01  7.33360765e-01]\n",
      " [ 6.15916736e-01 -7.39436754e-01]\n",
      " [-3.94887922e-01 -1.04435151e+00]\n",
      " [ 4.99569261e-02  8.14989021e-01]\n",
      " [-3.11229874e-01  7.71425929e-01]\n",
      " [ 3.36728927e-01 -6.86303636e-01]\n",
      " [-1.21124971e-01 -3.32328254e-02]\n",
      " [-1.85101347e-01  6.15444779e-01]\n",
      " [ 1.71756576e-01 -7.16188575e-01]\n",
      " [-2.06434210e-01  9.44415877e-01]\n",
      " [-7.44279423e-02  3.66019126e-01]\n",
      " [-4.91684469e-02  7.11036159e-01]\n",
      " [ 9.29894537e-02 -6.53150545e-01]\n",
      " [-1.84910022e+00  3.61811099e-01]\n",
      " [ 4.69344689e-01 -6.02548262e-01]\n",
      " [ 1.01069879e+00 -1.02203737e+00]\n",
      " [-5.19410838e-02 -6.51651581e-01]\n",
      " [ 7.85340452e-01  8.32314393e-02]\n",
      " [ 6.21836107e-02 -7.81838509e-01]\n",
      " [-4.69630859e-02 -1.01039798e+00]\n",
      " [ 1.74281441e+00 -9.40390875e-01]\n",
      " [-3.55186104e-01  5.74115944e-01]\n",
      " [ 2.38375263e-01 -6.64128156e-01]\n",
      " [ 8.45621049e-01  7.46030612e-01]\n",
      " [ 1.55352693e-01  4.34537551e-01]\n",
      " [-2.16299429e-01  7.25969100e-01]\n",
      " [-2.72349026e-01 -5.42490996e-01]\n",
      " [ 2.37458935e-01 -4.51122093e-01]\n",
      " [-7.05707663e-01  6.09939475e-01]\n",
      " [-1.43704915e-02  7.58485223e-01]\n",
      " [-1.71450982e+00  8.15657621e-01]\n",
      " [ 2.90121432e-02 -6.82308365e-01]\n",
      " [ 1.09050317e-01 -3.37407030e-01]\n",
      " [ 2.10263733e-01 -8.11132505e-01]\n",
      " [-1.31667793e+00 -8.59818643e-01]\n",
      " [ 1.23403436e-01 -7.53198578e-01]\n",
      " [-1.89505574e-01 -6.98661823e-01]\n",
      " [-1.69154056e-01  6.76285250e-01]\n",
      " [-5.10083145e-02  6.65066579e-01]\n",
      " [-7.21952195e-02  7.25912271e-01]\n",
      " [-1.36717212e-01  7.97187229e-01]\n",
      " [ 1.24986425e-01 -6.90992271e-01]\n",
      " [-7.66079476e-03 -5.39965567e-01]\n",
      " [-9.28541195e-02  6.11890752e-01]\n",
      " [ 9.87898563e-02 -5.84086011e-01]\n",
      " [-1.45160795e+00 -5.01417005e-01]\n",
      " [ 4.28157315e-02  6.13851469e-01]\n",
      " [ 9.68823742e-02  6.93097020e-01]\n",
      " [ 4.34498764e-01 -4.30814228e-01]\n",
      " [-4.98741108e-01  2.12677477e-01]\n",
      " [-1.32111025e-02 -7.68868580e-01]\n",
      " [-1.34187898e-01  7.40835255e-01]\n",
      " [ 1.71194405e+00 -5.46785627e-01]\n",
      " [ 2.14331905e-01 -5.77242801e-01]\n",
      " [-1.96724081e-02  7.24091473e-01]\n",
      " [-1.11040392e-01  7.03148920e-01]\n",
      " [-1.19897608e-01 -8.16217875e-01]\n",
      " [-9.56723684e-02  7.21410368e-01]\n",
      " [ 5.14678367e-01  5.92276006e-01]\n",
      " [-2.60880290e-01  5.79030180e-01]\n",
      " [ 6.91562238e-02 -8.72798696e-01]\n",
      " [ 5.62944883e-02 -7.07224930e-01]\n",
      " [-3.61528231e-02  8.34524639e-01]\n",
      " [-5.02068503e-01  7.91011028e-01]\n",
      " [ 1.65069305e-01 -7.66959370e-01]\n",
      " [ 7.51626670e-02 -6.87163536e-01]\n",
      " [-1.31866948e-02  6.61176912e-01]\n",
      " [-4.84033532e-01 -7.51297985e-01]\n",
      " [ 2.27258226e-01  6.42215096e-01]\n",
      " [-1.39624261e-01  7.01923835e-01]\n",
      " [-1.00461399e-01  7.45410337e-01]\n",
      " [ 4.46873124e-02 -7.39023507e-01]\n",
      " [-1.21351314e+00  6.42535379e-01]\n",
      " [ 5.73206035e-02  2.84515321e-01]\n",
      " [-1.23144056e-01  7.19666388e-01]\n",
      " [ 1.33155484e-01  8.87690208e-01]\n",
      " [-4.82981287e-01 -2.97403182e-01]\n",
      " [-8.95144563e-02  6.85514331e-01]\n",
      " [ 9.34704508e-02 -7.63342031e-01]\n",
      " [-5.54235436e-02  7.34912362e-01]\n",
      " [ 1.14454204e-01 -7.18524213e-01]\n",
      " [ 3.11844102e-01 -7.80189970e-01]\n",
      " [ 4.55847047e-02 -6.57101450e-01]\n",
      " [ 2.00876254e-01 -7.16349628e-01]\n",
      " [ 5.48191614e-02  7.49234037e-01]\n",
      " [-5.45645090e-02  6.91838777e-01]\n",
      " [-5.95123922e-01  9.51751709e-01]\n",
      " [ 1.59285788e-01 -6.77444186e-01]\n",
      " [-1.69244085e-01  7.06405196e-01]\n",
      " [-2.09130684e-01  6.80528504e-01]\n",
      " [ 1.75127302e+00 -1.15177840e+00]\n",
      " [-1.71248498e-01  7.60801278e-01]\n",
      " [ 1.11328509e-01 -6.52007754e-01]\n",
      " [-3.58631844e-01  7.02414092e-01]\n",
      " [-7.83749036e-02  7.03039694e-01]\n",
      " [ 3.50489254e-02 -7.10228529e-01]\n",
      " [-9.57773666e-01 -8.46147971e-01]\n",
      " [ 8.98293312e-02 -7.03691619e-01]\n",
      " [ 1.29741786e+00 -1.00663728e+00]\n",
      " [-3.60540820e-02  5.36968097e-01]\n",
      " [-8.00225834e-02  6.65114740e-01]\n",
      " [-2.43038791e-01  7.59862778e-01]\n",
      " [-7.84078873e-02  7.46420688e-01]\n",
      " [ 1.29249276e-01 -7.18345008e-01]\n",
      " [ 7.10034054e-02 -7.40550761e-01]\n",
      " [ 5.31966639e-03 -6.87327012e-01]\n",
      " [ 6.70211008e-02 -7.02073242e-01]\n",
      " [-3.76392255e-02 -7.16609116e-01]\n",
      " [ 6.93151407e-02 -6.42265851e-01]\n",
      " [ 1.63958448e+00 -8.79264936e-01]\n",
      " [-4.04225317e-01  4.26159706e-01]\n",
      " [-2.58313299e-02  6.74910276e-01]\n",
      " [-9.31583640e-01  8.50311043e-01]\n",
      " [ 1.56945237e+00 -6.12958752e-01]\n",
      " [-1.88137213e-02 -6.89826159e-01]\n",
      " [ 1.40727368e-01 -7.37719225e-01]\n",
      " [-1.28834820e-01  8.60291511e-01]\n",
      " [-1.80579790e-01  4.18421719e-01]\n",
      " [-1.01613972e-01  7.01845906e-01]\n",
      " [-1.08573957e-01 -6.58748261e-01]\n",
      " [-1.18480838e-01  7.59462798e-01]\n",
      " [ 9.94279837e-02 -7.32702364e-01]\n",
      " [ 1.34299093e-02  6.78817773e-01]\n",
      " [ 1.44220337e-01 -6.43519597e-01]\n",
      " [-1.39829326e-01  6.58406395e-01]\n",
      " [ 1.01119006e-01 -6.86957476e-01]\n",
      " [ 3.79756972e-02  6.60768572e-01]\n",
      " [-1.17155684e-01  6.87010936e-01]\n",
      " [-1.08059986e-01  7.21193133e-01]\n",
      " [-7.16058638e-02  7.09977340e-01]\n",
      " [-1.63442450e+00  5.29358959e-01]\n",
      " [-5.30858929e-02  7.47845873e-01]\n",
      " [-8.57442824e-02  6.46289717e-01]\n",
      " [ 8.71552984e-02  5.44076224e-01]\n",
      " [-4.46704899e-02  7.18952633e-01]\n",
      " [-1.03865098e-01  7.33787936e-01]\n",
      " [ 7.97605396e-02 -7.07966618e-01]\n",
      " [-2.81190471e-01  8.38162178e-01]\n",
      " [-9.67269786e-02  6.93711317e-01]\n",
      " [ 1.78037451e-01 -6.79216522e-01]\n",
      " [ 2.83577978e-01 -6.71447986e-01]\n",
      " [-9.99513096e-02  7.88531053e-01]\n",
      " [ 1.55528398e+00  6.06375715e-01]\n",
      " [ 1.02128040e-01 -7.14783009e-01]\n",
      " [ 1.75580928e+00 -7.60702218e-01]\n",
      " [ 1.12773737e-01 -7.01416925e-01]\n",
      " [-3.14900922e-02 -6.07010455e-01]\n",
      " [-3.71418160e-01  7.89962278e-01]\n",
      " [-1.69595173e-01 -4.37858431e-01]\n",
      " [ 8.28936762e-02 -7.42379078e-01]\n",
      " [ 1.41785492e-01 -7.01289167e-01]\n",
      " [ 5.62840944e-02 -6.91526804e-01]\n",
      " [ 1.11153738e-01 -7.29684591e-01]\n",
      " [-5.10039258e-01  5.64867587e-01]\n",
      " [-1.61878484e-01  5.89800506e-01]\n",
      " [ 5.03988823e-02 -7.18794047e-01]\n",
      " [ 6.74803677e-01  1.00148327e+00]\n",
      " [-1.28883950e-01  6.83671130e-01]\n",
      " [-1.78303563e-02  6.93788905e-01]\n",
      " [ 2.78259182e-02 -7.54519624e-01]\n",
      " [ 7.03793952e-02 -7.17608244e-01]\n",
      " [ 2.04112029e-01 -7.34917619e-01]\n",
      " [-8.87089216e-02  7.31438741e-01]\n",
      " [-1.31682344e-01  7.16276903e-01]\n",
      " [ 5.94156983e-02 -6.09456014e-01]\n",
      " [ 1.10773895e-01 -6.76834939e-01]\n",
      " [ 1.65332707e-01 -5.33664548e-01]\n",
      " [-2.07773364e-03 -6.49881682e-01]\n",
      " [-4.39745444e-02  5.88408673e-01]\n",
      " [ 1.37434546e-01 -7.18234470e-01]\n",
      " [-1.62094976e+00  7.06987455e-01]\n",
      " [-1.57797988e-01  6.37387557e-01]\n",
      " [-5.62701786e-02 -7.92822372e-01]\n",
      " [ 2.02878689e-01 -6.84015809e-01]\n",
      " [ 1.61340828e-01 -1.76825667e-01]\n",
      " [ 1.77056018e-01  7.05731880e-01]\n",
      " [-2.07728043e-01 -1.69374647e-01]\n",
      " [ 2.83547416e-01 -7.18862185e-01]\n",
      " [ 7.59779872e-02 -6.88557726e-01]\n",
      " [ 2.82589213e-01  8.27009124e-01]\n",
      " [-5.73563434e-02 -6.90915682e-01]\n",
      " [ 4.20826996e-03  7.30113591e-01]\n",
      " [ 8.79908323e-02 -7.23516171e-01]\n",
      " [-6.28183125e-02  6.79716366e-01]\n",
      " [ 1.11960058e-01 -7.83808140e-01]\n",
      " [ 4.06840884e-02 -7.19977887e-01]\n",
      " [ 1.27900363e-01 -7.45681157e-01]\n",
      " [ 6.62257923e-02 -7.26433408e-01]\n",
      " [-5.24221361e-02  6.32821479e-01]\n",
      " [ 4.07950191e-01 -9.14328848e-01]\n",
      " [-1.00797739e-01  7.09541261e-01]\n",
      " [-6.52877415e-02  7.21740982e-01]\n",
      " [ 4.28725887e-01 -6.90121416e-01]\n",
      " [-2.00081192e-01  7.67237398e-01]\n",
      " [ 2.76267378e-02 -6.62776899e-01]\n",
      " [ 1.09230925e+00  2.20914583e-01]\n",
      " [ 1.03097366e-01 -7.19666292e-01]\n",
      " [ 4.12060430e-03  4.14323046e-01]\n",
      " [ 6.43252288e-01 -8.67633480e-01]\n",
      " [-9.08217258e-01  4.62326531e-01]\n",
      " [ 2.38317279e-01 -7.84913333e-01]\n",
      " [-1.22384191e-01  7.27507521e-01]\n",
      " [-1.06961735e-01  7.07653594e-01]\n",
      " [ 2.58896873e-01 -6.17053674e-01]\n",
      " [-9.69163877e-02  7.25223826e-01]\n",
      " [-1.38808825e+00  7.65625853e-01]\n",
      " [-6.16015591e-03 -7.98716028e-01]\n",
      " [-9.21411034e-02  7.46588227e-01]\n",
      " [-2.16835740e-01  6.18126276e-01]\n",
      " [-6.93861096e-02 -5.56174259e-01]\n",
      " [ 8.34621607e-02 -5.37340529e-01]\n",
      " [ 1.57102459e-01 -6.11736262e-01]\n",
      " [-1.19394833e-01  8.11045371e-01]\n",
      " [ 6.28320399e-02 -6.60069355e-01]\n",
      " [ 5.50344939e-02 -7.28414959e-01]\n",
      " [ 1.19099082e-02 -5.80034222e-01]\n",
      " [ 5.59416217e-02 -7.55724798e-01]\n",
      " [ 1.12411976e-01 -7.00237672e-01]\n",
      " [ 1.37252807e-01 -7.68726384e-01]\n",
      " [ 1.75428678e-01  5.36537211e-01]\n",
      " [ 3.18329440e-01 -1.01703213e+00]\n",
      " [ 2.62010318e-02 -6.96387274e-01]\n",
      " [ 8.58902437e-02 -7.53039151e-01]\n",
      " [-1.85774981e-01  7.28103830e-01]\n",
      " [ 8.55032539e-02 -7.09568055e-01]\n",
      " [ 1.18733329e-01  1.46650437e-01]\n",
      " [-1.59136252e+00  9.64343551e-01]\n",
      " [ 7.45917722e-02 -8.12184930e-01]\n",
      " [-1.71772353e-01  7.99545669e-01]\n",
      " [ 1.01376372e-01  7.67408832e-01]\n",
      " [-1.17749896e-01  7.38213204e-01]\n",
      " [-4.19187938e-02  6.99188903e-01]\n",
      " [ 5.43022052e-02  6.92405883e-01]\n",
      " [ 1.16767903e+00 -4.95130897e-01]\n",
      " [ 7.42392222e-01 -6.43248321e-01]\n",
      " [ 2.49299033e-01 -8.50311168e-01]\n",
      " [-4.24851921e-02  6.82841002e-01]\n",
      " [ 1.23956971e-02 -6.74922409e-01]\n",
      " [-5.88636406e-02 -7.48544751e-01]\n",
      " [ 1.36819600e-01 -6.83371765e-01]\n",
      " [ 1.01190900e-01 -7.47470477e-01]\n",
      " [ 1.08271453e-01 -6.25092018e-01]\n",
      " [ 2.91048147e-02 -6.50346585e-01]\n",
      " [ 9.95712467e-02 -6.97006148e-01]\n",
      " [-1.43532056e-01  6.90281429e-01]\n",
      " [-1.91894633e-01  5.21378341e-01]\n",
      " [ 8.41460651e-02 -6.75818877e-01]\n",
      " [-8.58738601e-02  7.08366282e-01]\n",
      " [ 3.03194258e-01  3.97287134e-01]\n",
      " [ 5.94236192e-02 -6.94723430e-01]\n",
      " [-6.84616227e-02  4.67702380e-01]\n",
      " [ 1.24949700e-01 -6.58779707e-01]\n",
      " [-1.32851719e-01  6.19521882e-01]\n",
      " [-3.33978432e-01 -8.18598576e-01]\n",
      " [ 9.35167100e-02 -7.24994720e-01]\n",
      " [ 1.39000535e-01 -7.77246828e-01]\n",
      " [-9.33551122e-02  7.16056347e-01]\n",
      " [-5.90021845e-01  6.81256255e-01]\n",
      " [-1.15875717e-01  7.21282766e-01]\n",
      " [-2.85784350e-01  7.44073293e-01]\n",
      " [ 2.79891752e-02 -8.00984739e-01]\n",
      " [ 1.64167990e-03 -6.99298824e-01]\n",
      " [-1.80523613e+00  5.50477352e-02]\n",
      " [-3.31732902e-01  6.54620822e-01]\n",
      " [-4.39874669e-02  7.76700230e-01]\n",
      " [-2.64217424e-01  7.92266759e-01]\n",
      " [-1.12596551e+00  1.02514915e+00]\n",
      " [-1.42260681e-01  7.19372156e-01]\n",
      " [ 1.41362025e-02 -7.41707429e-01]\n",
      " [-1.43784186e-01  7.57581090e-01]\n",
      " [ 9.21051602e-02 -6.99552729e-01]\n",
      " [ 3.02610817e-01  8.78817891e-02]\n",
      " [-6.21122496e-02 -9.00230836e-01]\n",
      " [-1.11479142e-02  7.15979243e-01]\n",
      " [ 1.61671300e-02 -7.64782001e-01]\n",
      " [ 1.70133217e-02 -4.86852272e-01]\n",
      " [-1.43283233e-01 -2.80719341e-01]\n",
      " [-3.73483187e-02  7.01052890e-01]\n",
      " [-1.87768188e-01  1.31900045e-01]\n",
      " [-7.04685561e-02  6.99166262e-01]\n",
      " [ 1.00389933e-01 -6.15450867e-01]\n",
      " [-1.26038576e-01  7.07617092e-01]\n",
      " [-1.93029964e-01 -7.69550994e-01]\n",
      " [ 9.88022894e-01 -7.90174709e-01]\n",
      " [-8.86131236e-02 -6.28139706e-01]\n",
      " [-9.20119725e-01 -3.39820907e-01]\n",
      " [ 1.95826292e-02 -9.11225034e-02]\n",
      " [ 8.21134260e-01 -3.99826947e-01]\n",
      " [ 1.52640950e-01 -7.21948635e-01]\n",
      " [ 5.54247467e-01 -6.68294401e-01]\n",
      " [-1.83175233e-01  7.41722476e-01]\n",
      " [-2.41684888e-01  7.00086399e-01]\n",
      " [ 9.02856631e-02 -7.18477590e-01]\n",
      " [ 2.14624135e-01 -7.69327482e-01]\n",
      " [-2.20575654e-01  7.39395580e-01]\n",
      " [ 4.05498106e-02  8.68977351e-01]\n",
      " [ 7.56969507e-02 -6.46745117e-01]\n",
      " [ 1.12399184e-01 -7.26936010e-01]\n",
      " [ 7.97422512e-03  7.50641526e-01]\n",
      " [-9.38135238e-03  6.73412413e-01]\n",
      " [-7.13593283e-02  5.79020868e-01]\n",
      " [ 1.54294290e-01 -7.41948345e-01]\n",
      " [ 2.38321464e-01 -7.16805698e-01]\n",
      " [ 1.47857964e-01 -5.83033488e-01]\n",
      " [ 1.66663471e+00  4.36356358e-02]\n",
      " [ 1.89370447e-01 -6.54693305e-01]\n",
      " [ 3.67638899e-01 -6.21107583e-01]\n",
      " [ 1.71868221e-01 -7.38161082e-01]]\n",
      "[ 2.26933131e+00  1.50605531e+00  1.79978347e+00  2.72432776e+00\n",
      "  1.61674509e+01  8.45427849e-01  1.01380554e+01  1.49355479e+00\n",
      "  5.70857563e-01  1.70029870e+01  2.46890371e+00  1.79308103e+00\n",
      "  3.58922758e-01  1.57252436e+00  1.58629706e+01 -1.96480621e-02\n",
      "  5.29737387e-01 -1.32532202e-01 -1.01117642e+00 -3.11236851e-01\n",
      "  1.05638146e+00  2.52972198e+01  1.05693553e+02  2.35001570e+00\n",
      " -5.25970524e-01  4.77827636e+01 -6.33962475e-01  2.92855492e-01\n",
      " -7.21960510e-01  4.82548813e+01  1.16082001e+02  2.23044885e+00\n",
      "  2.85646660e+01  3.10109956e+00  3.03296710e+01  1.88213158e+01\n",
      "  1.21493937e+00  3.19316442e+00  1.78972458e+01  5.88533391e+01\n",
      "  3.83945862e+01  2.06529300e+01  3.06075716e+00  1.01867044e+01\n",
      "  6.10892778e+01  5.56732242e-01  2.25596531e+00 -3.09219594e-01\n",
      "  6.92593245e-01  1.47900561e+01  8.82967130e+00  3.79680448e+00\n",
      "  2.93828067e+00  3.53370646e+01  5.11671870e+00  9.76418566e-01\n",
      "  3.63414536e+00 -2.83985149e-01  1.48542418e+00  5.52091310e-01\n",
      "  3.97664025e+01  3.26713968e+01  2.58045128e+01  9.93844455e+01\n",
      "  9.42208564e+01 -4.46317613e-01  6.79989441e-01  6.57227049e-01\n",
      "  2.13500031e+00 -1.03042730e+00 -1.86337002e-01  1.53278814e+00\n",
      "  2.32075918e-01  1.09179206e-01 -5.75741223e-01  4.34634832e-01\n",
      " -5.27057382e-01  2.54891938e-01 -6.84851005e-01 -7.10309228e-01\n",
      " -5.31456373e-01 -7.14127352e-01 -8.80232123e-01 -9.30315378e-01\n",
      " -5.88637184e-02 -7.86211363e-01  2.56745418e-02  2.30622734e+00\n",
      " -1.06591076e-02 -9.74835775e-01 -6.87741339e-02 -1.42035685e-01\n",
      " -8.85193605e-01  3.23141387e-01  1.65207777e-01 -8.90221233e-01\n",
      " -3.89200731e-01  3.87308130e-01  4.82091107e-01  6.80743597e-02\n",
      "  6.92961178e-01 -9.80788751e-01 -9.51238402e-01 -9.44153858e-01\n",
      " -7.91316273e-01  1.02435305e+00  2.44491061e+00 -9.30222094e-01\n",
      "  2.95947329e-01  5.59090039e-01 -8.00721064e-01 -8.00090171e-02\n",
      "  1.24274823e+00 -2.77806766e-01 -9.51071113e-01 -6.45515504e-01\n",
      "  2.22049637e+00 -5.60832217e-01  1.49108640e+00 -9.96580051e-01\n",
      "  8.60779994e-01  1.52982226e+00 -1.01246207e+00 -2.13280753e-01\n",
      "  1.38191222e+00 -8.41460058e-01 -8.35860765e-01 -8.00704416e-01\n",
      "  5.78465924e-02 -9.20536802e-01 -1.00615949e+00 -4.13877937e-01\n",
      " -4.69236519e-01 -1.02517846e+00 -1.00475783e+00  1.32624595e+00\n",
      " -4.24999524e-01  1.40324933e+00 -9.32665664e-01  1.78426504e+00\n",
      " -9.83656370e-01  1.41627549e-01  6.81640867e-02 -6.15910653e-01\n",
      " -9.23847271e-01  1.55203859e+00 -4.49849296e-01 -9.71524708e-01\n",
      " -3.97719095e-01 -5.36570537e-01  1.47480769e-01 -9.87393592e-01\n",
      " -2.10126781e-01 -1.01168123e+00 -3.93055520e-01 -8.98009205e-01\n",
      "  2.72095589e+00 -1.01439796e+00 -7.26079421e-01 -9.94383410e-01\n",
      " -1.01021984e+00 -1.02871089e+00 -9.61505237e-01 -1.02235908e+00\n",
      " -8.21844448e-01 -9.59393823e-01 -9.17938668e-01  2.19809315e+00\n",
      " -9.05692277e-01 -8.93951842e-01 -1.09248310e-01  5.91353563e-01\n",
      " -9.55904554e-01 -1.01852433e+00  3.02084559e-01 -8.33091619e-01\n",
      " -1.01033332e+00 -1.02895207e+00 -7.34563454e-01 -1.03091190e+00\n",
      "  3.12301803e-01 -7.79909448e-01 -7.67167154e-01 -1.02715756e+00\n",
      " -8.70604764e-01 -4.53746682e-01 -9.88026558e-01 -1.02602555e+00\n",
      " -9.92225224e-01  2.06437287e-01 -6.22354773e-01 -1.02060817e+00\n",
      " -1.02234684e+00 -1.01652411e+00  6.51566625e-01 -2.68156393e-01\n",
      " -1.02716210e+00 -4.79774003e-01  6.44180903e-01 -1.02582991e+00\n",
      " -1.00921185e+00 -1.02203336e+00 -1.02913891e+00 -8.26604044e-01\n",
      " -1.00303637e+00 -9.85197520e-01 -9.31869917e-01 -1.02403446e+00\n",
      "  2.60464753e-01 -1.00101901e+00 -1.00669184e+00 -9.65925008e-01\n",
      "  1.84686663e+00 -9.89930035e-01 -1.00090127e+00 -7.71295445e-01\n",
      " -1.03047776e+00 -1.01990390e+00  2.15647580e+00 -1.03097862e+00\n",
      "  1.12068501e+00 -8.34955117e-01 -1.01441441e+00 -9.31705202e-01\n",
      " -1.02095170e+00 -1.02558206e+00 -1.02309281e+00 -1.00050018e+00\n",
      " -1.02892750e+00 -9.66632662e-01 -9.94727629e-01 -9.06091762e-02\n",
      " -1.67802273e-01 -1.00684612e+00  5.14463597e-01  1.92837844e-01\n",
      " -9.83275308e-01 -1.01759651e+00 -8.14424008e-01 -5.25043229e-01\n",
      " -1.03001950e+00 -8.64164361e-01 -1.01066088e+00 -1.02807983e+00\n",
      " -9.84013580e-01 -9.81012858e-01 -9.96966336e-01 -1.02562738e+00\n",
      " -9.53072026e-01 -1.02284059e+00 -1.02989090e+00 -1.03031792e+00\n",
      "  3.81931850e-01 -1.01439092e+00 -9.99021217e-01 -7.55884619e-01\n",
      " -1.02300104e+00 -1.02739511e+00 -1.03109981e+00 -7.68324165e-01\n",
      " -1.02845128e+00 -9.90256038e-01 -8.72483056e-01 -9.79740250e-01\n",
      "  2.11916745e+00 -1.03103039e+00 -1.71377181e-01 -1.02831181e+00\n",
      " -9.07711440e-01 -7.19145618e-01 -4.32274375e-01 -1.02369637e+00\n",
      " -1.01959757e+00 -1.02437209e+00 -1.02779718e+00 -2.52854442e-01\n",
      " -8.99512800e-01 -1.02496890e+00  2.10518749e+00 -1.01799845e+00\n",
      " -1.00970670e+00 -9.98689449e-01 -1.02984788e+00 -9.80546215e-01\n",
      " -1.02863719e+00 -1.02490828e+00 -9.56002353e-01 -1.01918722e+00\n",
      " -7.95207032e-01 -9.74512001e-01 -9.23560521e-01 -1.02289792e+00\n",
      " -8.73364224e-02 -9.67127973e-01 -8.76625239e-01 -9.73540214e-01\n",
      " -4.69815273e-02 -7.51689000e-01  9.24450666e-02 -8.94512205e-01\n",
      " -1.02661372e+00 -3.24749905e-01 -9.45185850e-01 -9.92483244e-01\n",
      " -1.03061455e+00 -1.02117511e+00 -9.85635850e-01 -1.02132706e+00\n",
      " -1.01793728e+00 -1.02753519e+00 -9.82566946e-01 -3.12357288e-01\n",
      " -1.03104827e+00 -1.02836009e+00 -6.27274190e-01 -9.65286336e-01\n",
      " -1.00050767e+00  2.40483439e+00 -1.03063184e+00 -5.67005620e-01\n",
      "  1.66695730e-02  9.65560329e-01 -9.12684213e-01 -1.02616757e+00\n",
      " -1.03020059e+00 -8.44099936e-01 -1.03020640e+00  2.62238032e-01\n",
      " -9.18810175e-01 -1.02180642e+00 -8.94948254e-01 -7.96779650e-01\n",
      " -8.38553796e-01 -9.35373596e-01 -9.40643359e-01 -1.00917245e+00\n",
      " -1.02424943e+00 -8.99332925e-01 -1.00954697e+00 -1.02813013e+00\n",
      " -9.97819029e-01 -6.04761475e-01  2.02504509e-01 -1.01459570e+00\n",
      " -1.01729189e+00 -9.96069194e-01 -1.03149063e+00 -1.07890269e-02\n",
      "  2.80493846e-01 -9.36446249e-01 -9.43548368e-01 -8.49691198e-01\n",
      " -1.02378204e+00 -1.02179095e+00 -9.48930993e-01  1.07642522e+00\n",
      "  1.74691127e-01 -7.72445324e-01 -1.01724715e+00 -9.99837780e-01\n",
      " -9.27549771e-01 -1.01499714e+00 -1.02111019e+00 -9.73325876e-01\n",
      " -9.91794972e-01 -1.02914557e+00 -1.01534890e+00 -7.47350021e-01\n",
      " -1.02116165e+00 -1.03143422e+00 -6.10230663e-02 -1.02597910e+00\n",
      " -6.96901449e-01 -1.00294631e+00 -9.58355648e-01 -1.90363006e-01\n",
      " -1.03035302e+00 -9.88176909e-01 -1.03149720e+00 -2.44739585e-01\n",
      " -1.02860817e+00 -8.88268856e-01 -9.39110935e-01 -1.00065490e+00\n",
      "  2.15819146e+00 -7.81527002e-01 -9.83780153e-01 -8.74992860e-01\n",
      "  1.43490254e+00 -1.02101884e+00 -9.99633650e-01 -1.00526518e+00\n",
      " -1.03019826e+00  3.44879022e-01 -5.43252874e-01 -1.00684691e+00\n",
      " -9.82492696e-01 -7.30502220e-01 -1.68913041e-01 -1.02031695e+00\n",
      "  4.52853659e-02 -1.02895894e+00 -9.62908094e-01 -1.02617069e+00\n",
      " -6.71299820e-01  4.94823502e-01 -8.68587953e-01  1.98765278e+00\n",
      " -3.31882722e-02  9.78970428e-01 -1.01633824e+00 -3.18746188e-01\n",
      " -9.93943158e-01 -9.42262167e-01 -1.03135052e+00 -9.51528922e-01\n",
      " -9.64685127e-01 -6.97843462e-01 -9.99392281e-01 -1.02827280e+00\n",
      " -9.77649814e-01 -9.97310647e-01 -9.12454072e-01 -1.01024129e+00\n",
      " -9.49592136e-01 -8.97266318e-01  2.11701522e+00 -9.62841655e-01\n",
      " -6.73059455e-01 -1.00247792e+00]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" gp.py\n",
    "Bayesian optimisation of loss functions.\n",
    "\"\"\"\n",
    "# Code modified from Bayesian Optimization tutorial \"Bayesian optimization with scikit-learn\" \n",
    "# https://github.com/thuijskens/bayesian-optimization   - Linked in tutortial\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.gaussian_process as gp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def expected_improvement(x, gaussian_process, evaluated_loss, greater_is_better=False, n_params=1):\n",
    "    \"\"\" expected_improvement\n",
    "    Expected improvement acquisition function.\n",
    "    Arguments:\n",
    "    ----------\n",
    "        x: array-like, shape = [n_samples, n_hyperparams]\n",
    "            The point for which the expected improvement needs to be computed.\n",
    "        gaussian_process: GaussianProcessRegressor object.\n",
    "            Gaussian process trained on previously evaluated hyperparameters.\n",
    "        evaluated_loss: Numpy array.\n",
    "            Numpy array that contains the values off the loss function for the previously\n",
    "            evaluated hyperparameters.\n",
    "        greater_is_better: Boolean.\n",
    "            Boolean flag that indicates whether the loss function is to be maximised or minimised.\n",
    "        n_params: int.\n",
    "            Dimension of the hyperparameter space.\n",
    "    \"\"\"\n",
    "\n",
    "    x_to_predict = x.reshape(-1, n_params)\n",
    "\n",
    "    mu, sigma = gaussian_process.predict(x_to_predict, return_std=True)\n",
    "\n",
    "    if greater_is_better:\n",
    "        loss_optimum = np.max(evaluated_loss)\n",
    "    else:\n",
    "        loss_optimum = np.min(evaluated_loss)\n",
    "\n",
    "    scaling_factor = (-1) ** (not greater_is_better)\n",
    "\n",
    "    # In case sigma equals zero\n",
    "    with np.errstate(divide='ignore'):\n",
    "        Z = scaling_factor * (mu - loss_optimum) / sigma\n",
    "        expected_improvement = scaling_factor * (mu - loss_optimum) * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "        expected_improvement[sigma == 0.0] == 0.0\n",
    "\n",
    "    return -1 * expected_improvement\n",
    "\n",
    "\n",
    "def sample_next_hyperparameter(acquisition_func, gaussian_process, evaluated_loss, greater_is_better=False,\n",
    "                               bounds=(0, 10), n_restarts=25):\n",
    "    \"\"\" sample_next_hyperparameter\n",
    "    Proposes the next hyperparameter to sample the loss function for.\n",
    "    Arguments:\n",
    "    ----------\n",
    "        acquisition_func: function.\n",
    "            Acquisition function to optimise.\n",
    "        gaussian_process: GaussianProcessRegressor object.\n",
    "            Gaussian process trained on previously evaluated hyperparameters.\n",
    "        evaluated_loss: array-like, shape = [n_obs,]\n",
    "            Numpy array that contains the values off the loss function for the previously\n",
    "            evaluated hyperparameters.\n",
    "        greater_is_better: Boolean.\n",
    "            Boolean flag that indicates whether the loss function is to be maximised or minimised.\n",
    "        bounds: Tuple.\n",
    "            Bounds for the L-BFGS optimiser.\n",
    "        n_restarts: integer.\n",
    "            Number of times to run the minimiser with different starting points.\n",
    "    \"\"\"\n",
    "    best_x = None\n",
    "    best_acquisition_value = 1\n",
    "    n_params = bounds.shape[0]\n",
    "\n",
    "    for starting_point in np.random.uniform(bounds[:, 0], bounds[:, 1], size=(n_restarts, n_params)):\n",
    "\n",
    "        res = minimize(fun=acquisition_func,\n",
    "                       x0=starting_point.reshape(1, -1),\n",
    "                       bounds=bounds,\n",
    "                       method='L-BFGS-B',\n",
    "                       args=(gaussian_process, evaluated_loss, greater_is_better, n_params))\n",
    "\n",
    "        if res.fun < best_acquisition_value:\n",
    "            best_acquisition_value = res.fun\n",
    "            best_x = res.x\n",
    "\n",
    "    return best_x\n",
    "\n",
    "\n",
    "def bayesian_optimisation(n_iters, sample_loss, bounds, x0=None, n_pre_samples=5,\n",
    "                          gp_params=None, random_search=False, alpha=1e-5, epsilon=1e-7):\n",
    "    \"\"\" bayesian_optimisation\n",
    "    Uses Gaussian Processes to optimise the loss function `sample_loss`.\n",
    "    Arguments:\n",
    "    ----------\n",
    "        n_iters: integer.\n",
    "            Number of iterations to run the search algorithm.\n",
    "        sample_loss: function.\n",
    "            Function to be optimised.\n",
    "        bounds: array-like, shape = [n_params, 2].\n",
    "            Lower and upper bounds on the parameters of the function `sample_loss`.\n",
    "        x0: array-like, shape = [n_pre_samples, n_params].\n",
    "            Array of initial points to sample the loss function for. If None, randomly\n",
    "            samples from the loss function.\n",
    "        n_pre_samples: integer.\n",
    "            If x0 is None, samples `n_pre_samples` initial points from the loss function.\n",
    "        gp_params: dictionary.\n",
    "            Dictionary of parameters to pass on to the underlying Gaussian Process.\n",
    "        random_search: integer.\n",
    "            Flag that indicates whether to perform random search or L-BFGS-B optimisation\n",
    "            over the acquisition function.\n",
    "        alpha: double.\n",
    "            Variance of the error term of the GP.\n",
    "        epsilon: double.\n",
    "            Precision tolerance for floats.\n",
    "    \"\"\"\n",
    "\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "\n",
    "    n_params = bounds.shape[0]\n",
    "\n",
    "    if x0 is None:\n",
    "        for params in np.random.uniform(bounds[:, 0], bounds[:, 1], (n_pre_samples, bounds.shape[0])):\n",
    "            x_list.append(params)\n",
    "            y_list.append(sample_loss(params))\n",
    "    else:\n",
    "        for params in x0:\n",
    "            x_list.append(params)\n",
    "            y_list.append(sample_loss(params))\n",
    "\n",
    "    xp = np.array(x_list)\n",
    "    yp = np.array(y_list)\n",
    "\n",
    "    # Create the GP\n",
    "    if gp_params is not None:\n",
    "        model = gp.GaussianProcessRegressor(**gp_params)\n",
    "    else:\n",
    "        kernel = gp.kernels.Matern()\n",
    "        model = gp.GaussianProcessRegressor(kernel=kernel,\n",
    "                                            alpha=alpha,\n",
    "                                            n_restarts_optimizer=10,\n",
    "                                            normalize_y=True)\n",
    "\n",
    "    for n in range(n_iters):\n",
    "\n",
    "        model.fit(xp, yp)\n",
    "\n",
    "        # Sample next hyperparameter\n",
    "        if random_search:\n",
    "            x_random = np.random.uniform(bounds[:, 0], bounds[:, 1], size=(random_search, n_params))\n",
    "            ei = -1 * expected_improvement(x_random, model, yp, greater_is_better=False, n_params=n_params)\n",
    "            next_sample = x_random[np.argmax(ei), :]\n",
    "        else:\n",
    "            next_sample = sample_next_hyperparameter(expected_improvement, model, yp, greater_is_better=False, bounds=bounds, n_restarts=100)\n",
    "\n",
    "        # Duplicates will break the GP. In case of a duplicate, we will randomly sample a next query point.\n",
    "        if np.any(np.abs(next_sample - xp) <= epsilon):\n",
    "            next_sample = np.random.uniform(bounds[:, 0], bounds[:, 1], bounds.shape[0])\n",
    "\n",
    "        # Sample loss for new set of parameters\n",
    "        cv_score = sample_loss(next_sample)\n",
    "\n",
    "        # Update lists\n",
    "        x_list.append(next_sample)\n",
    "        y_list.append(cv_score)\n",
    "\n",
    "        # Update xp and yp\n",
    "        xp = np.array(x_list)\n",
    "        yp = np.array(y_list)\n",
    "\n",
    "    return xp, yp\n",
    "\n",
    "n = 425\n",
    "nPreSamples = 5\n",
    "\n",
    "Eqn = lambda x: (4-2.1*x[0]**2+((x[0]**4)/3))*x[0]**2+x[0]*x[1]+(-4+4*(x[1]**2))*(x[1]**2)\n",
    "bounds = np.array([[-3, 3],[-2,2]])\n",
    "bOp1, bOp2 = bayesian_optimisation(n, Eqn, bounds, x0=None, n_pre_samples=5, gp_params=None, random_search=False, alpha=1e-5, epsilon=1e-7)\n",
    "\n",
    "plt.plot(np.linspace(1,(n+nPreSamples),(n+nPreSamples)),bOp2)\n",
    "plt.show\n",
    "\n",
    "print(\"Graph shows that we converge, therefore, we can take the last values\")\n",
    "\n",
    "print(bOp1)\n",
    "print(bOp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe82050",
   "metadata": {},
   "source": [
    "1.71868221e-01 -7.38161082e-01"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
